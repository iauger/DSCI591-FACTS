{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae97c58d",
   "metadata": {},
   "source": [
    "\n",
    "# 02 · Cleaning & Preprocessing\n",
    "\n",
    "**Purpose**  \n",
    "Transform raw datasets in `../data/raw/` into **clean, canonical** files in `../data/clean/` using the project’s cleaning utilities.  \n",
    "This notebook is a thin wrapper around the module logic so the pipeline remains testable and re-runnable.\n",
    "\n",
    "**What happens here**  \n",
    "- Convert formats when needed (e.g., JSON → JSONL, Parquet → CSV if previously created)\n",
    "- Apply dataset-specific normalization:\n",
    "  - FEVER: evidence structure normalization\n",
    "  - HotpotQA: `supporting_facts` and `context` flattening\n",
    "  - SQuAD v2: robust answer field parsing and text normalization\n",
    "- Copy passthrough files to `clean/` when no custom cleaning is required\n",
    "\n",
    "**Non-goals**  \n",
    "No plotting, statistics, or modeling. EDA lives in `03_eda.ipynb` and feature creation in `04_feature_engineering.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "470c59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & Path Setup ---\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb52d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\iauge\\Documents\\Drexel MSDS\\DSCI 591\\DSCI591-FACTS\n",
      "Raw dir: C:\\Users\\iauge\\Documents\\Drexel MSDS\\DSCI 591\\DSCI591-FACTS\\data\\raw\n",
      "Clean dir: C:\\Users\\iauge\\Documents\\Drexel MSDS\\DSCI 591\\DSCI591-FACTS\\data\\clean\n",
      "Imported: data_acquisition.data_cleaner.main\n"
     ]
    }
   ],
   "source": [
    "# Ensure project root on sys.path\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "CLEAN_DIR = PROJECT_ROOT / \"data\" / \"clean\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Raw dir:\", RAW_DIR)\n",
    "print(\"Clean dir:\", CLEAN_DIR)\n",
    "\n",
    "# Try both import paths depending on repo layout\n",
    "\n",
    "from data_acquisition.data_cleaner import main as run_cleaner\n",
    "print(\"Imported: data_acquisition.data_cleaner.main\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc6f00",
   "metadata": {},
   "source": [
    "## Run the Dataset Cleaning Script\n",
    "\n",
    "The `cleaner.py` script processes raw QA datasets from the `/data/raw/` directory and transforms them into clean, BigQuery-compatible CSV files stored in `/data/clean/`.\n",
    "\n",
    "This script uses the `DataCleaner` class, which includes dataset-specific parsing and normalization logic to:\n",
    "- **Standardize nested answer formats** (e.g., from arrays or dictionaries),\n",
    "- **Escape problematic characters** (e.g., rogue quotes or newline characters),\n",
    "- **Validate presence of required fields** (`id`, `title`, `context`, `question`, `answers`),\n",
    "- **Log and isolate failures** in a separate `*_failed.csv` file for inspection.\n",
    "\n",
    "Key features:\n",
    "- Handling of inconsistencies across datasets with diverse schemas (e.g., FEVER, HotpotQA, SQuAD).\n",
    "- Inline cleaning functions for each dataset ensure modular, extensible preprocessing logic.\n",
    "- All successfully cleaned rows are written to `/data/clean/`, and any rows with malformed or incomplete data are written to `/data/raw/*_failed.csv`.\n",
    "    - The logic was used exclusively for **SQuAD v2.0** during implementation as it was the most problematic to convert from raw to a cleaned version\n",
    "\n",
    "> **Note:** This step is essential before loading data into BigQuery, as unescaped quotes and inconsistent schemas will cause ingestion to fail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2cd5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run Cleaning ---\n",
    "\n",
    "run_cleaner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f2500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in C:\\Users\\iauge\\Documents\\Drexel MSDS\\DSCI 591\\DSCI591-FACTS\\data\\clean (10):\n",
      " - fever_dev_train.jsonl  (6.47 MB)\n",
      " - hotpot_dev_distractor.jsonl  (61.01 MB)\n",
      " - hotpot_dev_fullwiki.jsonl  (62.63 MB)\n",
      " - hotpot_train.jsonl  (737.53 MB)\n",
      " - nq_open_train.jsonl  (8.21 MB)\n",
      " - squad_v2_train.csv  (115.07 MB)\n",
      " - squad_v2_validation.csv  (11.50 MB)\n",
      " - truthful_qa_train.csv  (0.48 MB)\n",
      " - truthful_qa_with_source_text.csv  (9.88 MB)\n",
      " - truthfulqa_missing_urls.csv  (0.09 MB)\n"
     ]
    }
   ],
   "source": [
    "# --- Post-clean Sanity Checks ---\n",
    "\n",
    "clean_files = sorted(CLEAN_DIR.glob(\"*\"))\n",
    "print(f\"Files in {CLEAN_DIR} ({len(clean_files)}):\")\n",
    "for f in clean_files:\n",
    "    sz = f.stat().st_size / (1024 * 1024)\n",
    "    print(f\" - {f.name}  ({sz:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe79f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply additional cleaning for Truthful_QA\n",
    "# TODO: Implement this logic inside of the cleaner.py module and remove this section\n",
    "\n",
    "def clean_text(text):\n",
    "    return ' '.join(str(text).strip().split())\n",
    "\n",
    "df_clean = pd.read_csv(CLEAN_DIR / \"truthful_qa_train.csv\")\n",
    "\n",
    "df_clean['Question'] = df_clean['Question'].apply(clean_text)\n",
    "df_clean['Best Answer'] = df_clean['Best Answer'].apply(clean_text)\n",
    "df_clean['Best Incorrect Answer'] = df_clean['Best Incorrect Answer'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b975ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing and flatenning lists\n",
    "\n",
    "df_clean['Correct Answers'] = df_clean['Correct Answers'].apply(lambda x: [s.strip() for s in x.split(';')])\n",
    "df_clean['Incorrect Answers'] = df_clean['Incorrect Answers'].apply(lambda x: [s.strip() for s in x.split(';')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e5f293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write back to CSV\n",
    "df_clean.to_csv(CLEAN_DIR / \"truthful_qa_train.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
